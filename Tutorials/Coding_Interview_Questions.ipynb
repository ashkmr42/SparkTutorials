{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61f6ef-a1a7-49cf-8c3c-21c45eec57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How can you create a DataFrame a) using existing RDD, and b) from a CSV file?\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "spark = SparkSession.builder.appName(\"IntQues\").getOrCreate()\n",
    "sales_File = \"D:\\Jupyter\\Data\\sales_records.csv\"\n",
    "file_data = spark.read.format(\"csv\").option(\"header\",\"true\").load(sales_File)\n",
    "print(type(file_data)) #dataframe\n",
    "\n",
    "#Creating RDD from existing DF\n",
    "file_data_rdd = file_data.rdd\n",
    "df_schema = file_data.schema\n",
    "\n",
    "#Creating dataframe from RDD\n",
    "file_data_df = file_data_rdd.toDF()\n",
    "\n",
    "#RDD Schema\n",
    "file_data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b786961-a76f-406b-b1c3-ffc1564c3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain the use of StructType and StructField classes in PySpark with examples.\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "\n",
    "df_schema= StructType([StructField(\"Name\",StringType(),True),\n",
    "                       StructField(\"Age\",IntegerType(),True),\n",
    "                       StructField(\"Marks\",IntegerType(),True)])\n",
    "\n",
    "df_data = [(\"Ashish\",30,75),\n",
    "           (\"Himani\",45,77),\n",
    "          (\"Kaashvi\",1,87)]\n",
    "\n",
    "new_df = spark.createDataFrame(df_data,df_schema)\n",
    "new_df.show()\n",
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98c3ea-3077-4372-bc32-614a537beb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What are the different ways to handle row duplication in a PySpark DataFrame?\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "\n",
    "sales_schema = StructType([StructField(\"Name\",StringType(),True),\n",
    "                           StructField(\"Department\",StringType(),True),\n",
    "                           StructField(\"Salary\",IntegerType(),True)])\n",
    "\n",
    "sales_data = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100), \n",
    "    (\"Maria\", \"Finance\", 3000), \n",
    "    (\"James\", \"Sales\", 3000), \n",
    "    (\"Scott\", \"Finance\", 3300), \n",
    "    (\"Jen\", \"Finance\", 3900), \n",
    "    (\"Jeff\", \"Marketing\", 3000), \n",
    "    (\"Kumar\", \"Marketing\", 2000), \n",
    "    (\"Saif\", \"Sales\", 4100) ]\n",
    "\n",
    "sales_df = spark.createDataFrame(sales_data,sales_schema)\n",
    "sales_df.show()\n",
    "\n",
    "#Distinct\n",
    "sales_df_distinct = sales_df.distinct()\n",
    "sales_df.select([\"Department\",\"Salary\"]).distinct().show()\n",
    "#sales_df_distinct.show()\n",
    "\n",
    "#DropDuplicates\n",
    "sales_df_duplicate = sales_df.dropDuplicates()\n",
    "#sales_df_duplicate.show()\n",
    "\n",
    "#Dropduplicates based on columns\n",
    "sales_df_dupCol = sales_df.dropDuplicates([\"Department\",\"Salary\"])\n",
    "sales_df_dupCol.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe719dfa-7aee-4cf0-832e-2876114c9a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
